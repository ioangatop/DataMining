{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "John's copy DM2 Pipeline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX3qG4zQ9_-y",
        "colab_type": "text"
      },
      "source": [
        "# 2019 VU Data Mining Techniques Cup\n",
        "\n",
        "link: https://www.kaggle.com/t/81fd4b6b248c4642930d5c1013af967a\n",
        "\n",
        "__TASK__: \"Predict what hotels properties listed as a result of a hotel search a user is most likely to click on.\"\n",
        "\n",
        " __Evaluation metric__: Normalized Discounted Cumulative Gain (NDCG).\n",
        " \n",
        " \n",
        "### DATASET\n",
        "\n",
        "For a very nice overview on the data fields of the task,  refer to https://www.kaggle.com/c/expedia-personalized-sort/data .\n",
        "\n",
        "* Note: test.csv does not contain the following columns: position, click_bool, gross_bookings_usd, nor booking_bool\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLfGlw_c0LeH",
        "colab_type": "text"
      },
      "source": [
        "## Dicussion Board\n",
        "\n",
        "#### Done!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASkqt6kSb3cU",
        "colab_type": "text"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PejfipdtcBh7",
        "colab_type": "code",
        "outputId": "647a7623-0a86-4eff-ad20-6b7d93c62b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "# Install dependencies\n",
        "!pip install PyDrive\n",
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-3ayC1Eb3cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from scipy import stats\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "import copy \n",
        "import random\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "pd.set_option('display.max_column',None)\n",
        "pd.set_option('display.max_rows',None)\n",
        "pd.set_option('display.max_seq_items',None)\n",
        "pd.set_option('display.max_colwidth', 500)\n",
        "pd.set_option('expand_frame_repr', True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx56RD3kcHp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if \"training_set_VU_DM.csv\" not in os.listdir():\n",
        "    !mkdir .kaggle\n",
        "    # Create API Token for my account\n",
        "    token = {\"username\":\"pollendo\",\"key\":\"8666602a92bda984143ce79eca66ae75\"}\n",
        "    with open(\".kaggle/kaggle.json\", \"w\") as file:\n",
        "        json.dump(token, file)\n",
        "    !kaggle config set -n path -v/content\n",
        "\n",
        "    !cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "    !chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "    # download\n",
        "    !kaggle competitions download -c vu-dmt-2assignment\n",
        "    # unzip\n",
        "    !unzip training_set_VU_DM.csv\n",
        "    !unzip test_set_VU_DM.csv\n",
        "    !unzip submission_sample.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0nFwZkIb3ce",
        "colab_type": "text"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_1SI4cfb3cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set these global variables to switch between local validation or Kaggle submission\n",
        "DATA_FRACTION = 0.01\n",
        "TESTING = False\n",
        "\n",
        "if TESTING:\n",
        "    DATA_FRACTION = 1.0\n",
        "    with open(\"test_set_VU_DM.csv\",'r') as f_test:\n",
        "        test_rows = sum(1 for row in f_test)\n",
        "    test_set = pd.read_csv('test_set_VU_DM.csv', nrows=round(DATA_FRACTION*test_rows))\n",
        "\n",
        "\n",
        "with open(\"training_set_VU_DM.csv\",'r') as f_train:\n",
        "    train_rows = sum(1 for row in f_train)\n",
        "\n",
        "training_set = pd.read_csv('training_set_VU_DM.csv', nrows=round(DATA_FRACTION*train_rows))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ73axmEb3ci",
        "colab_type": "text"
      },
      "source": [
        "# Feature Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQyAG_-kb3cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################ Normalize df per feat #################\n",
        "def norm(df, feature):\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    # Create x, where x the 'scores' column's values as floats\n",
        "    x = df[[feature]].values.astype(float)\n",
        "\n",
        "    # Create a minimum and maximum processor object\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "    # Create an object to transform the data to fit minmax processor\n",
        "    x_scaled = min_max_scaler.fit_transform(x)\n",
        "\n",
        "    # Run the normalizer on the dataframe\n",
        "    df[feature] = x_scaled\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "###################### TARGET #########################\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def get_target(df):\n",
        "    df['target'] = 0.8 * 0.5 * (df.booking_bool.astype(float) + df.click_bool.astype(float)) \\\n",
        "        + 0.2 * sigmoid(np.log(df.position.astype(float))*df.click_bool.astype(float)\n",
        "                 + (1/df.position.astype(float))*(1-df.click_bool.astype(float)))\n",
        "    \n",
        "    df = norm(df, 'target')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "####################### Time ##########################\n",
        "def get_time_feat(df):\n",
        "    df.insert(2, 'time', df.date_time.dt.time)\n",
        "    df.insert(3, 'weekday', df.date_time.dt.dayofweek)\n",
        "    df.insert(4, 'month', df.date_time.dt.month)\n",
        "    df.date_time = df.date_time.dt.date\n",
        "    df = df.drop(['date_time'], axis=1)\n",
        "    df = df.drop(['time'], axis=1)   \n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "################### Per search score ###################\n",
        "def ratio(data, feature, new_feat_name, inv=True):\n",
        "\n",
        "    d = {'srch_id': data.srch_id.values, feature: data[feature].values}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    \n",
        "    avg_feat_per_scrch = df\n",
        "    avg_feat_per_scrch = avg_feat_per_scrch.rename(columns={feature: 'median_feat'})\n",
        "    avg_feat_per_scrch = avg_feat_per_scrch.groupby('srch_id', as_index=False).median()\n",
        "    \n",
        "    df = df.merge(avg_feat_per_scrch, on='srch_id', how='left')\n",
        "\n",
        "    if not inv:\n",
        "        data[new_feat_name] = df.median_feat / (df[feature] + 1)\n",
        "    else:\n",
        "        data[new_feat_name] = df[feature] / ( df.median_feat + 1)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_hotelworth(data):\n",
        "        data = ratio(data, 'price_usd', 'diff_price_per_srch', False)\n",
        "        data = ratio(data, 'prop_starrating', 'diff_star1_per_srch') \n",
        "        data = ratio(data, 'prop_review_score', 'diff_star2_per_srch')\n",
        "        data = ratio(data, 'prop_location_score1', 'diff_loc1_per_srch')\n",
        "        data = ratio(data, 'prop_location_score2', 'diff_loc2_per_srch')\n",
        "\n",
        "        data.diff_star1_per_srch = data.diff_star1_per_srch.fillna(0)\n",
        "        data.diff_star2_per_srch = data.diff_star2_per_srch.fillna(0)\n",
        "        data.diff_loc2_per_srch = data.diff_loc2_per_srch.fillna(0)\n",
        "        data.diff_price_per_srch = data.diff_price_per_srch.fillna(0)\n",
        "\n",
        "        df_hotel_worth = 0.3*(0.8*data['diff_star1_per_srch'] + 0.2*data['diff_star2_per_srch']) \\\n",
        "        + 0.3*(0.9*data['diff_loc2_per_srch'] + 0.1*data['diff_loc1_per_srch'])  \\\n",
        "        + 0.1*(np.log(data['diff_price_per_srch']))\n",
        "\n",
        "                    \n",
        "        data['hotel_worth'] = df_hotel_worth / 5\n",
        "        \n",
        "        # Normalize hotel_woth by scrh\n",
        "#         srch_ls = df.srch_id.unique()\n",
        "#         for e,srch in enumerate(srch_ls):\n",
        "#           print(\"{} / {}\".format(e, len(srch_ls)))\n",
        "#           df[df.srch_id == srch] = norm(df[df.srch_id == srch], 'hotel_worth')\n",
        "\n",
        "        return data\n",
        "    \n",
        "\n",
        "############# User's Preferences score #################\n",
        "def gaussian(x, mu, sig):\n",
        "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
        "\n",
        "def per_cent_avg_std(df, category1, category2):\n",
        "    \"\"\"\n",
        "    NOTE: category1 has to be the user's entry\n",
        "    \n",
        "    category1: str of feature\n",
        "    category2: str of feature\n",
        "    \n",
        "    \"\"\"\n",
        "    # Get a df of the two categories only\n",
        "    diff_df = df[[category1, category2]]\n",
        "    \n",
        "    # Clean NaNs\n",
        "    diff_df = diff_df[diff_df[category1].notnull()]\n",
        "    diff_df = diff_df[diff_df[category2].notnull()]\n",
        "\n",
        "    # Get the diff on % scale\n",
        "    diff_price = np.abs(diff_df[category1] - diff_df[category2])/diff_df[category1]\n",
        "\n",
        "    diff_price = diff_price[diff_price.values<10000]\n",
        "\n",
        "    # Get the mean\n",
        "    avg_std = diff_price.median()\n",
        "    \n",
        "    return avg_std\n",
        "\n",
        "def diff_score(df, customer_feature, hotel_feature):\n",
        "    \"\"\"\n",
        "    float [0,1]\n",
        "    \n",
        "    customer_feature: str of feature\n",
        "    hotel_feature: str of feature\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    df_booked = df[df.booking_bool == 1]\n",
        "    avg_std = per_cent_avg_std(df_booked, customer_feature, hotel_feature)\n",
        "\n",
        "    score_ = gaussian(df[hotel_feature], df[customer_feature]-df[customer_feature]*avg_std/2 , df[customer_feature]*avg_std)\n",
        "    \n",
        "    return avg_std, score_\n",
        "\n",
        "def diff_score_test(df, customer_feature, hotel_feature, avg_std):\n",
        "    score_ = gaussian(df[hotel_feature], df[customer_feature]-df[customer_feature]*avg_std/2 , df[customer_feature]*avg_std)\n",
        "    return score_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uijj2AU0b3cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add new features to the raw data set and create novel target value\n",
        "def gen_feat(df, target_, stds=None):\n",
        "    # Parse date_time\n",
        "    df['date_time'] = pd.to_datetime(df.date_time, format='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # Time features\n",
        "    df = get_time_feat(df)\n",
        "\n",
        "    # Total count of people\n",
        "    df.insert(24, 'srch_total_count', df['srch_adults_count'] + df['srch_children_count'])\n",
        "\n",
        "    # Per-srch hotel score\n",
        "    df = get_hotelworth(df)\n",
        "    \n",
        "    # Fill comp_columns with zero\n",
        "    comp_columns = ['comp1_rate', 'comp1_inv', 'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv', 'comp2_rate_percent_diff', 'comp3_rate',\n",
        "     'comp3_inv', 'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv', 'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv', 'comp5_rate_percent_diff',\n",
        "     'comp6_rate', 'comp6_inv', 'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv', 'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv', 'comp8_rate_percent_diff']\n",
        "    for i in comp_columns:\n",
        "      df[i] = df[i].fillna(0)\n",
        "\n",
        "    df = df.drop(columns=comp_columns, axis=1, errors=\"ignore\")\n",
        "    \n",
        "    if target_:\n",
        "        df = get_target(df)\n",
        "        \n",
        "        # Get rid of all non-clicked searches\n",
        "        df.insert(2, 'nr_clicks', df.groupby(\"srch_id\")[\"click_bool\"].transform(\"sum\"))\n",
        "        df = df[df[\"nr_clicks\"] > 0].drop(\"nr_clicks\", axis=1)\n",
        "        \n",
        "        # User's preferences\n",
        "        std_price, df['price_user_score'] = diff_score(df, 'visitor_hist_adr_usd', 'price_usd')\n",
        "        std_star1, df['star1_user_score'] = diff_score(df, 'visitor_hist_starrating', 'prop_starrating')\n",
        "        std_star2, df['star2_user_score'] = diff_score(df, 'visitor_hist_starrating', 'prop_review_score')\n",
        " \n",
        "        stds = []\n",
        "        stds.append(std_price)\n",
        "        stds.append(std_star1)\n",
        "        stds.append(std_star2)\n",
        "\n",
        "        df.price_user_score = df.price_user_score.fillna(0)\n",
        "        df.star1_user_score = df.star1_user_score.fillna(0)\n",
        "        df.star2_user_score = df.star2_user_score.fillna(0)\n",
        "\n",
        "        df['user_score_perf'] = (df.price_user_score + df.star1_user_score + df.star2_user_score) /3\n",
        "        \n",
        "        return stds, df\n",
        "\n",
        "    else:\n",
        "        df['price_user_score'] = diff_score_test(df, 'visitor_hist_adr_usd', 'price_usd', stds[0])\n",
        "        df['star1_user_score'] = diff_score_test(df, 'visitor_hist_starrating', 'prop_starrating', stds[1])\n",
        "        df['star2_user_score'] = diff_score_test(df, 'visitor_hist_starrating', 'prop_review_score', stds[2])\n",
        "        \n",
        "        df.price_user_score = df.price_user_score.fillna(0)\n",
        "        df.star1_user_score = df.star1_user_score.fillna(0)\n",
        "        df.star2_user_score = df.star2_user_score.fillna(0)\n",
        "\n",
        "        df['user_score_perf'] = (df.price_user_score + df.star1_user_score + df.star2_user_score) /3\n",
        "        \n",
        "        return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDMp6_cg0B87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = pd.read_csv('training_set_VU_DM.csv', nrows=round(DATA_FRACTION*train_rows))\n",
        "stds, df = gen_feat(training_set, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjlUKuGl4JFY",
        "colab_type": "code",
        "outputId": "d6109be3-5976-4341-97ff-e1a0404f777c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[df.srch_id == 6].hotel_worth.corr(df[df.srch_id == 6].target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7312408144067815"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LORizvE604GJ",
        "colab_type": "code",
        "outputId": "4e738ce8-684d-4196-950c-8a6a85b8c47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df[df.srch_id == 6].hotel_worth = df_temp.hotel_worth\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>srch_id</th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "      <th>site_id</th>\n",
              "      <th>visitor_location_country_id</th>\n",
              "      <th>visitor_hist_starrating</th>\n",
              "      <th>visitor_hist_adr_usd</th>\n",
              "      <th>prop_country_id</th>\n",
              "      <th>prop_id</th>\n",
              "      <th>prop_starrating</th>\n",
              "      <th>prop_review_score</th>\n",
              "      <th>prop_brand_bool</th>\n",
              "      <th>prop_location_score1</th>\n",
              "      <th>prop_location_score2</th>\n",
              "      <th>prop_log_historical_price</th>\n",
              "      <th>position</th>\n",
              "      <th>price_usd</th>\n",
              "      <th>promotion_flag</th>\n",
              "      <th>srch_destination_id</th>\n",
              "      <th>srch_length_of_stay</th>\n",
              "      <th>srch_booking_window</th>\n",
              "      <th>srch_adults_count</th>\n",
              "      <th>srch_children_count</th>\n",
              "      <th>srch_room_count</th>\n",
              "      <th>srch_total_count</th>\n",
              "      <th>srch_saturday_night_bool</th>\n",
              "      <th>srch_query_affinity_score</th>\n",
              "      <th>orig_destination_distance</th>\n",
              "      <th>random_bool</th>\n",
              "      <th>click_bool</th>\n",
              "      <th>gross_bookings_usd</th>\n",
              "      <th>booking_bool</th>\n",
              "      <th>diff_price_per_srch</th>\n",
              "      <th>diff_star1_per_srch</th>\n",
              "      <th>diff_star2_per_srch</th>\n",
              "      <th>diff_loc1_per_srch</th>\n",
              "      <th>diff_loc2_per_srch</th>\n",
              "      <th>hotel_worth</th>\n",
              "      <th>target</th>\n",
              "      <th>price_user_score</th>\n",
              "      <th>star1_user_score</th>\n",
              "      <th>star2_user_score</th>\n",
              "      <th>user_score_perf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100</td>\n",
              "      <td>10759</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.63</td>\n",
              "      <td>0</td>\n",
              "      <td>21106</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>652.84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1.166278</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100</td>\n",
              "      <td>22135</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>115.03</td>\n",
              "      <td>0</td>\n",
              "      <td>21106</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>652.84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.991382</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.087877</td>\n",
              "      <td>0.007903</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100</td>\n",
              "      <td>52376</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>86.03</td>\n",
              "      <td>0</td>\n",
              "      <td>21106</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>652.85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1.321728</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.660710</td>\n",
              "      <td>0.026001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100</td>\n",
              "      <td>104251</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>145.00</td>\n",
              "      <td>0</td>\n",
              "      <td>21106</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>652.84</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>162.38</td>\n",
              "      <td>1</td>\n",
              "      <td>0.787877</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.893584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100</td>\n",
              "      <td>118866</td>\n",
              "      <td>2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1.95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>183.66</td>\n",
              "      <td>0</td>\n",
              "      <td>21106</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>652.78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.622929</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.566277</td>\n",
              "      <td>0.017076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    srch_id  weekday  month  site_id  visitor_location_country_id  \\\n",
              "60        6        2      6       14                          100   \n",
              "61        6        2      6       14                          100   \n",
              "62        6        2      6       14                          100   \n",
              "63        6        2      6       14                          100   \n",
              "64        6        2      6       14                          100   \n",
              "\n",
              "    visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
              "60                      NaN                   NaN              100    10759   \n",
              "61                      NaN                   NaN              100    22135   \n",
              "62                      NaN                   NaN              100    52376   \n",
              "63                      NaN                   NaN              100   104251   \n",
              "64                      NaN                   NaN              100   118866   \n",
              "\n",
              "    prop_starrating  prop_review_score  prop_brand_bool  prop_location_score1  \\\n",
              "60                0                2.0                0                  1.95   \n",
              "61                0                5.0                0                  1.95   \n",
              "62                2                0.0                1                  1.95   \n",
              "63                3                4.0                1                  1.95   \n",
              "64                2                4.5                1                  1.95   \n",
              "\n",
              "    prop_location_score2  prop_log_historical_price  position  price_usd  \\\n",
              "60                   NaN                        0.0         4      97.63   \n",
              "61                   NaN                        0.0         6     115.03   \n",
              "62                   NaN                        0.0         2      86.03   \n",
              "63                   NaN                        0.0         1     145.00   \n",
              "64                   NaN                        0.0         3     183.66   \n",
              "\n",
              "    promotion_flag  srch_destination_id  srch_length_of_stay  \\\n",
              "60               0                21106                    1   \n",
              "61               0                21106                    1   \n",
              "62               0                21106                    1   \n",
              "63               0                21106                    1   \n",
              "64               0                21106                    1   \n",
              "\n",
              "    srch_booking_window  srch_adults_count  srch_children_count  \\\n",
              "60                    5                  2                    0   \n",
              "61                    5                  2                    0   \n",
              "62                    5                  2                    0   \n",
              "63                    5                  2                    0   \n",
              "64                    5                  2                    0   \n",
              "\n",
              "    srch_room_count  srch_total_count  srch_saturday_night_bool  \\\n",
              "60                1                 2                         0   \n",
              "61                1                 2                         0   \n",
              "62                1                 2                         0   \n",
              "63                1                 2                         0   \n",
              "64                1                 2                         0   \n",
              "\n",
              "    srch_query_affinity_score  orig_destination_distance  random_bool  \\\n",
              "60                        NaN                     652.84            0   \n",
              "61                        NaN                     652.84            0   \n",
              "62                        NaN                     652.85            0   \n",
              "63                        NaN                     652.84            0   \n",
              "64                        NaN                     652.78            0   \n",
              "\n",
              "    click_bool  gross_bookings_usd  booking_bool  diff_price_per_srch  \\\n",
              "60           0                 NaN             0             1.166278   \n",
              "61           0                 NaN             0             0.991382   \n",
              "62           0                 NaN             0             1.321728   \n",
              "63           1              162.38             1             0.787877   \n",
              "64           0                 NaN             0             0.622929   \n",
              "\n",
              "    diff_star1_per_srch  diff_star2_per_srch  diff_loc1_per_srch  \\\n",
              "60             0.000000                  0.4            0.661017   \n",
              "61             0.000000                  1.0            0.661017   \n",
              "62             0.666667                  0.0            0.661017   \n",
              "63             1.000000                  0.8            0.661017   \n",
              "64             0.666667                  0.9            0.661017   \n",
              "\n",
              "    diff_loc2_per_srch  hotel_worth    target  price_user_score  \\\n",
              "60                 0.0     0.000000  0.012513               0.0   \n",
              "61                 0.0     0.087877  0.007903               0.0   \n",
              "62                 0.0     0.660710  0.026001               0.0   \n",
              "63                 0.0     1.000000  0.893584               0.0   \n",
              "64                 0.0     0.566277  0.017076               0.0   \n",
              "\n",
              "    star1_user_score  star2_user_score  user_score_perf  \n",
              "60               0.0               0.0              0.0  \n",
              "61               0.0               0.0              0.0  \n",
              "62               0.0               0.0              0.0  \n",
              "63               0.0               0.0              0.0  \n",
              "64               0.0               0.0              0.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmATLM6G08Ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqVBL4MHG38N",
        "colab_type": "code",
        "outputId": "62a32b92-f235-4a9a-dbb5-51a21e5f6c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7312408144067812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpRrDXuZG3O0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# df[df.srch_id==101].sort_values(['hotel_worth'], ascending=[False])\n",
        "# # days, window, adults, children"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFAUfk-VJ_R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(df.diff_price_per_srch.corr(df.target))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_P4KwAXMf-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df[df.booking_bool==1].sort_values(['srch_length_of_stay'], ascending=[True]).head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71ORGT2337Oq",
        "colab_type": "code",
        "outputId": "3ee6f186-9035-4153-cd96-ecc41f0dcc11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-173-5f9e73fc76ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2224\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2226\u001b[0;31m                 raise TypeError(\"Cannot index by location index with a \"\n\u001b[0m\u001b[1;32m   2227\u001b[0m                                 \"non-integer key\")\n\u001b[1;32m   2228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot index by location index with a non-integer key"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBZeiB6Bb3co",
        "colab_type": "text"
      },
      "source": [
        "# Remove outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p7Ftavmb3cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find and remove outliers for each pre-defined feature\n",
        "def remove_outliers(input_data):\n",
        "    # Focus on these features, because IDs and Booleans do not make sense for outlier detection\n",
        "    features = ['prop_starrating', 'prop_location_score1', \n",
        "                'prop_log_historical_price', 'price_usd', 'srch_length_of_stay', 'srch_booking_window', \n",
        "                'srch_adults_count', 'srch_children_count', 'srch_room_count']\n",
        "        \n",
        "    indices_to_remove = []\n",
        "  \n",
        "    # Build the boundaries first, then find and remove outliers or replace them with their boundary\n",
        "    for column in features:\n",
        "        if is_numeric_dtype(input_data[column]):\n",
        "\n",
        "            # Calculate the interquartile range\n",
        "            Q1 = input_data[column].quantile(0.25)\n",
        "            Q3 = input_data[column].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            \n",
        "            if IQR == 0:\n",
        "                continue\n",
        "\n",
        "            # Calculate the maximum value and minimum values according to the Tukey rule\n",
        "            max_value = Q3 + 1.5 * IQR\n",
        "            min_value = Q1 - 1.5 * IQR\n",
        "            \n",
        "            # Iteratively build a list of indices to be removed\n",
        "            # Do not remove in place, because that will change the DataFrame and influence subsequent interquartile ranges for other columns\n",
        "            indices_to_remove = indices_to_remove + list(input_data.loc[(input_data[column].notnull()) & ((input_data[column] < min_value) | (input_data[column] > max_value))].index)\n",
        "\n",
        "    #for index in indices_to_remove:\n",
        "    indices_to_remove = list(set(indices_to_remove))\n",
        "    output_data = pd.concat([input_data[input_data[\"target\"] >= 0.4], input_data[input_data[\"target\"] < 0.4].drop(index=indices_to_remove, errors=\"ignore\")], axis=0)\n",
        "    return output_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zon1Xrcab3cr",
        "colab_type": "text"
      },
      "source": [
        "# Handle missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRDGONm4b3cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop all columns that have at least one NaN value\n",
        "def remove_nans(df):\n",
        "    # For speed, we drop NaN values\n",
        "    columns_with_na = df.columns[df.isnull().any()]\n",
        "    df = df.drop(columns_with_na, axis=1)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Replace NaN and Inf values of all numeric columns\n",
        "def replace_nans(data, unique_nan_values):\n",
        "  \n",
        "    # features = get_features(with_target=False)\n",
        "    \n",
        "    data = data.replace([np.inf, -np.inf], np.nan)\n",
        "    \n",
        "    for column in list(data):\n",
        "\n",
        "        if is_numeric_dtype(data[column]):\n",
        "            data[column] = data[column].fillna(unique_nan_values[column])\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etsCI9y1b3cu",
        "colab_type": "text"
      },
      "source": [
        "# Balance the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dPOvqtnb3cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removes non-clicked rows randomly up to a final ratio of 50/50 for clicked to non-clicked\n",
        "def balance_data(df, print_=False):\n",
        "    click_indices = df[df.click_bool == 1].index\n",
        "    random_indices = np.random.choice(click_indices, len(df.loc[df.click_bool == 1]), replace=False)\n",
        "    click_sample = df.loc[random_indices]\n",
        "\n",
        "    not_click = df[df.click_bool == 0].index\n",
        "    random_indices = np.random.choice(not_click, sum(df['click_bool']), replace=False)\n",
        "    not_click_sample = df.loc[random_indices]\n",
        "\n",
        "    df_new = pd.concat([not_click_sample, click_sample], axis=0)\n",
        "\n",
        "    if print_:\n",
        "        print(\"Percentage of not click impressions: \", len(df_new[df_new.click_bool == 0])/len(df_new))\n",
        "        print(\"Percentage of click impression: \", len(df_new[df_new.click_bool == 1])/len(df_new))\n",
        "        print(\"Total number of records in resampled data: \", len(df_new))\n",
        "\n",
        "    df = df_new.sort_values(['srch_id'], ascending=[True])\n",
        "    df = df.reset_index(drop=True)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHjcS4r8b3cy",
        "colab_type": "text"
      },
      "source": [
        "# Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRAzGWmTb3cz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splits the data into a training and validation set\n",
        "def split_data(train, ratio=0.7):\n",
        "    \n",
        "    temp_train = copy.deepcopy(train)\n",
        "    \n",
        "    uniq_searches = temp_train.srch_id.unique().tolist()\n",
        "    train_id = random.sample(uniq_searches, round(len(uniq_searches)*ratio))\n",
        "    \n",
        "    val_id = list(set(uniq_searches) - set(train_id))\n",
        "    \n",
        "    train_set = temp_train[temp_train['srch_id'].isin(train_id)]\n",
        "    validation_set = temp_train[temp_train['srch_id'].isin(val_id)]\n",
        "    \n",
        "    return train_set, validation_set\n",
        "\n",
        "# Splits the data into features and targets\n",
        "def prepare_features_and_targets(raw_df, testing=False):\n",
        "    list_of_columns_to_exclude = ['position', 'click_bool', 'booking_bool', 'target']\n",
        "\n",
        "    if testing:\n",
        "        return raw_df.drop(list_of_columns_to_exclude, axis=1, errors='ignore')\n",
        "    \n",
        "    df_t = raw_df.target\n",
        "    df_x = raw_df.drop(list_of_columns_to_exclude, axis=1, errors='ignore')\n",
        "    \n",
        "    return df_x, df_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7-o4aqcb3c2",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uZkXkjsb3c3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Trains a model on the given input and returns the predictions on the given validation set\n",
        "def regressor_fit(x_train, t_train, x_val, eval_on_train=False):\n",
        "    # Init model\n",
        "\n",
        "#     model = GradientBoostingRegressor(learning_rate=0.1, n_estimators=100,\n",
        "#                                      min_samples_split=2, min_samples_leaf=1,\n",
        "#                                      max_depth=2)\n",
        "\n",
        "#     model = AdaBoostRegressor(random_state=0, learning_rate=0.1, loss='square' ,n_estimators=65)\n",
        "    model = RandomForestRegressor(n_estimators=51,min_samples_leaf=5,min_samples_split=3)\n",
        "\n",
        "\n",
        "    # fit\n",
        "    model.fit(x_train, t_train)\n",
        "    if eval_on_train:\n",
        "        y_train = model.predict(x_train)\n",
        "        errors = abs(y_train - t_train)\n",
        "        print('Mean Absolute Error on Train:', round(np.mean(errors), 2), 'degrees.')\n",
        "    \n",
        "    y_val = model.predict(x_val)\n",
        "    return y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNkVWnE8b3c7",
        "colab_type": "text"
      },
      "source": [
        "# Ranking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_SkL788b3c9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns a dataframe that has been sorted with respect to predictions per srch_id\n",
        "def rank_df(data_to_be_ranked, predictions, validation=True):    \n",
        "    \n",
        "    df = data_to_be_ranked[['srch_id', 'prop_id']]\n",
        "    df.insert(2, 'predictions', predictions)\n",
        "    \n",
        "    if validation:\n",
        "        df.insert(3, 'target', data_to_be_ranked['target'])\n",
        "        df.insert(4, 'relevance', 4 * data_to_be_ranked['booking_bool'] + data_to_be_ranked['click_bool'])\n",
        "\n",
        "    # Sort them to get a ranking\n",
        "    df = df.sort_values(['srch_id', 'predictions'], ascending=[True, False])\n",
        "    \n",
        "    if not validation:\n",
        "        # Set file name\n",
        "        time = str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
        "        file_name = 'submission_' + time + '.csv'\n",
        "\n",
        "        df = df.drop(['predictions'],axis=1)\n",
        "        df.to_csv(file_name, header=True, index=False)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCUpmmmyb3dA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_dcg(ranking, cut=5):\n",
        "    len_ = min(cut, len(ranking))\n",
        "    dcg = ranking[:len_]    \n",
        "    result = 0\n",
        "    for i in range(1, len_):\n",
        "        result += (dcg[i-1]) / math.log(i+1, 2)\n",
        "    return result\n",
        "\n",
        "def compute_ndcg(val_set, val_pred):\n",
        "    ranked_val_set = rank_df(val_set, val_pred, validation=True)\n",
        "    ndcgs = []\n",
        "    for idx in ranked_val_set.srch_id.unique():\n",
        "\n",
        "        our_ranking = ranked_val_set[ranked_val_set['srch_id'] == idx][\"relevance\"].values\n",
        "        our_dcg = compute_dcg(our_ranking)\n",
        "\n",
        "        best_ranking = sorted(our_ranking, reverse=True)\n",
        "        best_dcg = compute_dcg(best_ranking)\n",
        "        \n",
        "        if best_dcg > 0:\n",
        "            ndcg = our_dcg / best_dcg\n",
        "        else:\n",
        "            ndcg = 0\n",
        "\n",
        "        ndcgs.append(ndcg)\n",
        "    return sum(ndcgs) / len(ndcgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF78h8GEcVNQ",
        "colab_type": "text"
      },
      "source": [
        "# Code execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "_Uhqcwyrb3dC",
        "colab_type": "code",
        "outputId": "f4b75290-1ece-4979-c3cf-2b42582235d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Preprocessing\n",
        "stds, df = gen_feat(training_set, True)\n",
        "df = remove_nans(df)\n",
        "if TESTING:\n",
        "    df_test = gen_feat(test_set, False, stds)\n",
        "    df_test = remove_nans(df_test)\n",
        "\n",
        "# Two cases: Validation or Testing!\n",
        "if not TESTING:\n",
        "    ndcg_cross_validation = []\n",
        "    folds = 3\n",
        "    \n",
        "    for i in range(folds):\n",
        "        \n",
        "        # Prepare training and validation for model\n",
        "        train_set, val_set = split_data(df, 0.95)\n",
        "        \n",
        "        # Potential additional preprocessing steps\n",
        "        \n",
        "        #train_set = remove_outliers(train_set)\n",
        "        train_set = balance_data(train_set)\n",
        "        \n",
        "        # Use this print statement to figure out a good split ratio\n",
        "        print(\"Shapes\", train_set.shape, val_set.shape)\n",
        "        \n",
        "        train_x, train_t = prepare_features_and_targets(train_set)\n",
        "        val_x, val_t = prepare_features_and_targets(val_set)\n",
        "\n",
        "        # Predict and rank validation set\n",
        "        val_y = regressor_fit(train_x, train_t, val_x)\n",
        "        ranking = rank_df(val_set, val_y, validation=True)\n",
        "        ndcg = compute_ndcg(val_set, val_y)\n",
        "        ndcg_cross_validation.append(ndcg)\n",
        "\n",
        "    print(\"All NDCGs\", ndcg_cross_validation)\n",
        "    print(\"Mean:\", sum(ndcg_cross_validation) / len(ndcg_cross_validation))\n",
        "\n",
        "else:\n",
        "\n",
        "    # Prepare training and validation for model\n",
        "    train_set = balance_data(df)\n",
        "    train_x, train_t = prepare_features_and_targets(train_set)\n",
        "    test_x = prepare_features_and_targets(df_test, testing=True)\n",
        "\n",
        "    # Predict and rank validation set\n",
        "    test_y = regressor_fit(train_x, train_t, test_x)\n",
        "    ranking = rank_df(test_x, test_y, validation=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes (84372, 36) (49196, 36)\n",
            "Shapes (84320, 36) (48448, 36)\n",
            "Shapes (84320, 36) (48641, 36)\n",
            "All NDCGs [0.3059036927754511, 0.3218183364092447, 0.29969679711668257]\n",
            "Mean: 0.3091396087671261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynthkgEi-_Yx",
        "colab_type": "text"
      },
      "source": [
        "# Exploration\n"
      ]
    }
  ]
}